spring.application.name=bvqa-backend
server.port=8080

# AI Provider Configuration
# Options: ollama, gemini, openai
app.ai.provider=ollama
app.embedding.store-file=./vector_store.json

# Ollama Configuration
# Default URL is http://localhost:11434
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=gemma3:12b

# Google Gemini Configuration
# API Key must be set in Environment Variable: PROPERTIES_GOOGLE_API_KEY
GOOGLE_GENERATIVE_AI_API_KEY=<abc>
langchain4j.google-ai-gemini.chat-model.api-key=${GOOGLE_GENERATIVE_AI_API_KEY:}
langchain4j.google-ai-gemini.chat-model.model-name=gemini-3-pro-preview

# OpenAI Configuration
# API Key must be set in Environment Variable: PROPERTIES_OPENAI_API_KEY
langchain4j.open-ai.chat-model.api-key=${PROPERTIES_OPENAI_API_KEY:}
langchain4j.open-ai.chat-model.model-name=gpt-3.5-turbo

# File Upload Limit
spring.servlet.multipart.max-file-size=10MB
spring.servlet.multipart.max-request-size=10MB
 
# PDF Ingestion Configuration
app.ingestion.input-dir=./documents_in
app.ingestion.processed-dir=./documents_processed
